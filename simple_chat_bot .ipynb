{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from itertools import islice\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## import the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import the data from \n",
    "#chat1 stores the chat of 1st person\n",
    "#chat2 stores the chat of 2nd person\n",
    "\n",
    "chat1=[]\n",
    "chat2=[]\n",
    "\n",
    "def yield_alt(f, option='odd'):\n",
    "    \n",
    "        if option == 'odd':\n",
    "            return islice(f, 0, None, 2)\n",
    "        return islice(f, 1, None, 2)\n",
    " \n",
    "with open('/home/hadoop-user1/chat_dataset1.txt') as f:\n",
    "    for line in yield_alt(f):      \n",
    "        chat1.append(line)\n",
    "\n",
    "with open('/home/hadoop-user1/chat_dataset1.txt') as f:\n",
    "    for line in yield_alt(f, 'even'):\n",
    "        chat2.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## showing some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['hi\\n',\n",
       "  'hi there how are you,\\n',\n",
       "  'i am  doing fine\\n',\n",
       "  'hi my name is expectations\\n',\n",
       "  'hello apeksha my best friend\\n'],\n",
       " ['hello\\n',\n",
       "  'i am fine how do you do\\n',\n",
       "  'what is your name\\n',\n",
       "  'you are indeed expectations\\n',\n",
       "  'apeksha is expectations\\n'])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat1,chat2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## tokenizes the list of strings and finds the vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#ques stores the tokenized list of chat1\n",
    "#ans stores tokenized list of chat2\n",
    "#words store total number of words\n",
    "#vocab_stores total number of unique words\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "ques,ans=[],[]\n",
    "words=[]\n",
    "\n",
    "for i in chat1:\n",
    "    \n",
    "        tr=map(str.lower,tokenizer.tokenize(i))\n",
    "        ques.append(tr)\n",
    "        words.extend(tr)\n",
    "        \n",
    "for i in chat2:\n",
    "    \n",
    "        tr=map(str.lower,tokenizer.tokenize(i)) \n",
    "        ans.append(tr)\n",
    "        words.extend(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size=len((set(words)))\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## finds dictionary of words (id to word and word to id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'apeksha',\n",
       "  1: 'do',\n",
       "  2: 'what',\n",
       "  3: 'friend',\n",
       "  4: 'your',\n",
       "  5: 'name',\n",
       "  6: 'i',\n",
       "  7: 'my',\n",
       "  8: 'doing',\n",
       "  9: 'there',\n",
       "  10: 'am',\n",
       "  11: 'expectations',\n",
       "  12: 'hello',\n",
       "  13: 'how',\n",
       "  14: 'hi',\n",
       "  15: 'are',\n",
       "  16: 'indeed',\n",
       "  17: 'you',\n",
       "  18: 'fine',\n",
       "  19: 'is',\n",
       "  20: 'best'},\n",
       " {'am': 10,\n",
       "  'apeksha': 0,\n",
       "  'are': 15,\n",
       "  'best': 20,\n",
       "  'do': 1,\n",
       "  'doing': 8,\n",
       "  'expectations': 11,\n",
       "  'fine': 18,\n",
       "  'friend': 3,\n",
       "  'hello': 12,\n",
       "  'hi': 14,\n",
       "  'how': 13,\n",
       "  'i': 6,\n",
       "  'indeed': 16,\n",
       "  'is': 19,\n",
       "  'my': 7,\n",
       "  'name': 5,\n",
       "  'there': 9,\n",
       "  'what': 2,\n",
       "  'you': 17,\n",
       "  'your': 4})"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word=dict(enumerate(set(words)))\n",
    "\n",
    "word_to_id={k:v for v,k in id_to_word.items()}\n",
    "id_to_word,word_to_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## data stores tokenized question and answer as a whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data=[]\n",
    "\n",
    "a=[data.append(i) for i in ques]\n",
    "a=[data.append(i) for i in ans]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Adding an empty string to the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Adds empty string corresponding the index added for padding in the later part part of code\n",
    "\n",
    "id_to_word[vocab_size]=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## converting words to indices of ques and ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# train and target stores the  indices corresponding to words of ques and ans\n",
    "\n",
    "train,target=[],[]\n",
    "\n",
    "for i in range(len(ques)):\n",
    "    \n",
    "    train.append([word_to_id[x] for x in ques[i]])\n",
    "    target.append([word_to_id[x] for x in ans[i]])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## padding to make all sequence of equal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# max_length calculates length of longest sequence and add 100 as a padding to make all sequence of equal length\n",
    "\n",
    "max_length = max([len(i) for i in data])\n",
    "\n",
    "for i in range(len(train)):\n",
    "    \n",
    "    train[i] =[j for j in train[i]] + [vocab_size] * (max_length - len(train[i]))\n",
    "\n",
    "    target[i] =[j for j in target[i]] + [vocab_size] * (max_length - len(target[i]))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = np.array(train)\n",
    "\n",
    "target = np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[14, 21, 21, 21, 21, 21, 21],\n",
       "        [14,  9, 13, 15, 17, 21, 21],\n",
       "        [ 6, 10,  8, 18, 21, 21, 21],\n",
       "        [14,  7,  5, 19, 11, 21, 21],\n",
       "        [12,  0,  7, 20,  3, 21, 21]]), array([[12, 21, 21, 21, 21, 21, 21],\n",
       "        [ 6, 10, 18, 13,  1, 17,  1],\n",
       "        [ 2, 19,  4,  5, 21, 21, 21],\n",
       "        [17, 15, 16, 11, 21, 21, 21],\n",
       "        [ 0, 19, 11, 21, 21, 21, 21]]))"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train,target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# one hot encoding is used as an embedding vector\n",
    "\n",
    "vec = np.zeros((vocab_size+1, vocab_size+1))\n",
    "\n",
    "for k in id_to_word.keys():\n",
    "    vec[k][k] = 1\n",
    "\n",
    "# constant tensor for word embedding(one hot)\n",
    "\n",
    "embed = tf.constant(vec, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'how', 'are', 'you', '', '', '']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ques = np.array([[14, 13, 15, 17, 21, 21, 21]])\n",
    "[id_to_word[i] for i in test_ques[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## initializing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_size = vocab_size+1\n",
    "output_size = vocab_size+1\n",
    "iterations = 5001\n",
    "hidden_layer = 60\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## initializing random weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Wxhe=tf.Variable(tf.random_normal(([input_size,hidden_layer]),0,0.1),dtype=tf.float32)\n",
    "\n",
    "Whhe=tf.Variable(tf.random_normal(([hidden_layer,hidden_layer]),0,0.1),dtype=tf.float32)\n",
    "\n",
    "Whye=tf.Variable(tf.random_normal(([hidden_layer,output_size]),0,0.1),dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Wxhd=tf.Variable(tf.random_normal(([input_size,hidden_layer]),0,0.1),dtype=tf.float32)\n",
    "\n",
    "Whhd=tf.Variable(tf.random_normal(([hidden_layer,hidden_layer]),0,0.1),dtype=tf.float32)\n",
    "\n",
    "Whyd=tf.Variable(tf.random_normal(([hidden_layer,output_size]),0,0.1),dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## function to train the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_nn(): # execution of training starts with this function\n",
    "    \n",
    "    with tf.variable_scope(\"train_nn\"):\n",
    "        \n",
    "        #placeholder for input, output and hidden state and previous outputs of encoder and decoder\n",
    "        \n",
    "        x=tf.placeholder(shape=[None,max_length], dtype=tf.int32) \n",
    "        y=tf.placeholder(shape=[None,None],dtype=tf.int32)\n",
    "        \n",
    "        hinit = tf.placeholder(shape=[None, hidden_layer], dtype=tf.float32)\n",
    "        xinit=tf.placeholder(shape=[None,vocab_size+1],dtype=tf.float32)\n",
    "        prob=tf.placeholder(shape=[None,vocab_size+1],dtype=tf.float32)\n",
    "        \n",
    "\n",
    "        #embedding target as one hot\n",
    "        Y_embed = tf.nn.embedding_lookup(embed,y)\n",
    "\n",
    "        # encoder_output is the context vector and encoder state is the hidden state of lat time space\n",
    "        encoder_output,encoder_state=encoder(x,hinit,xinit)\n",
    "\n",
    "        #decoder_output is the output of decoder(as an output of softmax layer)\n",
    "        decoder_output=decoder(x,encoder_output,encoder_state,prob)\n",
    "        decoder_output = tf.transpose(decoder_output, [1, 0, 2])\n",
    "        \n",
    "        #takes the argmax of output to find the indices of the corresponding word \n",
    "        decoder_output_arg=tf.argmax(decoder_output,axis=2)\n",
    "\n",
    "        #loss takes the mean of all the samples loss (loss function used is softmax_cross_entropy_with_logits)\n",
    "        loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=decoder_output,labels=Y_embed))\n",
    "        \n",
    "        optimizer=tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "        \n",
    "        with tf.Session() as session:\n",
    "\n",
    "            session.run(tf.global_variables_initializer()) #initializes the variables\n",
    "            session.run(tf.local_variables_initializer())\n",
    "            \n",
    "            #iterating the loop\n",
    "            for i in range(iterations):\n",
    "                \n",
    "                #runs the loss and optimizer function by feeding train, target and hidden state to their placeholders \n",
    "                #l is the loss at each iteration\n",
    "                \n",
    "                l,_=session.run([loss,optimizer],\n",
    "                feed_dict={x:train, y:target,hinit:np.zeros((5,hidden_layer)),xinit:np.zeros((5,vocab_size+1))\n",
    "                           ,prob:np.zeros((5,vocab_size+1))})\n",
    "                \n",
    "                \n",
    "                if i%1000==0:\n",
    "                    print \"loss for\",i,\"iteration:\",l\n",
    "                \n",
    "                #predict outputs the decoders output after each weight tuning at each iteration\n",
    "                \n",
    "                \n",
    "                predict = session.run(decoder_output_arg,\n",
    "                {x:train, y:target,hinit:np.zeros((5,hidden_layer)),xinit:np.zeros((5,vocab_size+1)),\n",
    "                 prob:np.zeros((5,vocab_size+1))})\n",
    "                \n",
    "                if(i%5000==0):\n",
    "                    \n",
    "                    for j in range(5):#print predicted result of four sample for simplicity\n",
    "\n",
    "                        print(\"chat1 : \", [[id_to_word[w] for w in sent] for sent in train][j])\n",
    "                        print(\"chat2 : \", [[id_to_word[w] for w in sent] for sent in predict][j])\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "            print\"---------Training over------------\"\n",
    "            \n",
    "            print \"---testing the trained model with test data----\"\n",
    "            \n",
    "            out_test = session.run(decoder_output_arg, {x:test_ques, \n",
    "                hinit: np.zeros((1, hidden_layer)),xinit:np.zeros((1,vocab_size+1)),\n",
    "                prob:np.zeros((1,vocab_size+1))})\n",
    "            \n",
    "            print(\"chat1 : \", [[id_to_word[w] for w in sent] for sent in test_ques])\n",
    "            print(\"chat_bot     : \", [[id_to_word[w] for w in sent] for sent in out_test])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## encoder function to find the context vector and hidden state of input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def encoder(X,hinit,xinit):#takes input sequence and initial hidden state and initial output \n",
    "    \n",
    "    with tf.variable_scope(\"encoder\"):\n",
    "        \n",
    "        #embedding for train to one hot\n",
    "        X_embed = tf.nn.embedding_lookup(embed,X)\n",
    "        X_embed = tf.transpose(X_embed, [1, 0, 2])\n",
    "\n",
    "        #list of hidden state and output\n",
    "        con=[hinit,xinit]\n",
    "        \n",
    "        #scans encoder's helper function RNN_enc \n",
    "        output= tf.scan(RNN_enc, X_embed, initializer=con)\n",
    "  \n",
    "        \n",
    "        h_t=output[0]\n",
    "        y_t=output[1]\n",
    "\n",
    "        #takes last hidden state and output\n",
    "        h_t=h_t[-1]\n",
    "        y_t=y_t[-1]\n",
    "\n",
    "\n",
    "        arg=tf.argmax(y_t,axis=1)\n",
    "        arg_one_hot=tf.nn.embedding_lookup(embed,(tf.cast(arg, tf.int32)))\n",
    "        \n",
    "        #returns one hot vector of encoder's output and hidden state\n",
    "        return arg_one_hot,h_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## encoder's helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def RNN_enc(h, x_t):#helper function of encoder (takes hidden states,output and input sequence)\n",
    "    \n",
    "    with tf.variable_scope('RNN_enc'):\n",
    "        \n",
    "            #reshapes input sequence\n",
    "            x_t = tf.reshape(x_t, [-1, input_size])\n",
    "            x_t=tf.cast(x_t, tf.float32)\n",
    "            \n",
    "            #reshapes hidden state\n",
    "            hprev = tf.reshape(h[0], [-1, hidden_layer])\n",
    "\n",
    "            #h_t calculates the wighted sum of inputs and hidden  state of previous layes \n",
    "            #and then pass it to the activation function\n",
    "            \n",
    "            h_t=tf.tanh(tf.matmul(hprev,Whhe) + tf.matmul(x_t,Wxhe))\n",
    "            h_t = tf.reshape(h_t, [-1, hidden_layer])\n",
    "\n",
    "            #out is the output from the softmax layer\n",
    "            out=tf.nn.softmax(tf.matmul(h_t,Whye))\n",
    "\n",
    "\n",
    "            x_and_h=[h_t,out]        \n",
    "\n",
    "            #reurns list of hidden state and ouput of encoder\n",
    "            return x_and_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## decoder function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def decoder(X,xprev,s,prob):\n",
    "    #takes input sequence  \n",
    "    #last hidden state from encoder \n",
    "    #initial input to decoder as a context vector \n",
    "    \n",
    "    with tf.variable_scope(\"decoder\"):\n",
    "        \n",
    "        #embedding for train to one hot\n",
    "        X_embed = tf.nn.embedding_lookup(embed,X)\n",
    "        X_embed = tf.transpose(X_embed, [1, 0, 2])\n",
    "\n",
    "        #list of hidden state,output of previous state\n",
    "        con=[s,xprev,prob]\n",
    "\n",
    "        #scans decoder's helper function RNN_enc \n",
    "        output= tf.scan(RNN_dec, X_embed, initializer=con)\n",
    "\n",
    "        h_dec=output[0]\n",
    "\n",
    "        out_prob=output[2]\n",
    "        \n",
    "        #returns output from decoder\n",
    "        return out_prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## decoder's helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def RNN_dec(h, x_t):\n",
    "     #takes hidden state of previous time state\n",
    "     #ouput of previous state\n",
    "     #input sequence just for the sake of working of scan function to iterate\n",
    "        \n",
    "    \n",
    "        with tf.variable_scope('RNN_dec'):\n",
    "            \n",
    "            hprev=h[0]\n",
    "            yprev=h[1]\n",
    "            \n",
    "            #reshape\n",
    "            hprev = tf.reshape(h[0], [-1, hidden_layer])\n",
    "\n",
    "            yprev = tf.reshape(h[1], [-1, input_size])\n",
    "\n",
    "            #h_t calculates the wighted sum of inputs and hidden  state of previous layes \n",
    "            #and then pass it to the activation function\n",
    "            \n",
    "            h_t=tf.tanh(tf.matmul(yprev,Wxhd )+ tf.matmul(hprev,Whhd))\n",
    "            \n",
    "            h_t = tf.reshape(h_t, [-1, hidden_layer])\n",
    "\n",
    "            #out is the output from the softmax layer\n",
    "            out=tf.nn.softmax(tf.matmul(h_t,Whyd))\n",
    "\n",
    "            arg=tf.argmax(out,axis=1)\n",
    "            arg_one_hot=tf.nn.embedding_lookup(embed,arg)\n",
    "\n",
    "            x_and_h=[h_t,arg_one_hot,out] \n",
    "            \n",
    "            #reurns list of hidden state and ouput of decoder\n",
    "            return x_and_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## function to start the execution of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 0 iteration: 3.09008\n",
      "('chat1 : ', ['hi', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['there', 'apeksha', 'what', 'how', 'my', '', ''])\n",
      "('chat1 : ', ['hi', 'there', 'how', 'are', 'you', '', ''])\n",
      "('chat2 : ', ['do', 'you', 'what', 'fine', 'expectations', 'friend', 'your'])\n",
      "('chat1 : ', ['i', 'am', 'doing', 'fine', '', '', ''])\n",
      "('chat2 : ', ['', 'apeksha', '', 'apeksha', 'are', 'am', 'i'])\n",
      "('chat1 : ', ['hi', 'my', 'name', 'is', 'expectations', '', ''])\n",
      "('chat2 : ', ['', 'apeksha', 'indeed', 'what', 'you', 'apeksha', 'you'])\n",
      "('chat1 : ', ['hello', 'apeksha', 'my', 'best', 'friend', '', ''])\n",
      "('chat2 : ', ['do', 'i', 'what', 'fine', 'are', 'name', 'doing'])\n",
      "loss for 1000 iteration: 2.19537\n",
      "loss for 2000 iteration: 2.16642\n",
      "loss for 3000 iteration: 2.16632\n",
      "loss for 4000 iteration: 2.16628\n",
      "loss for 5000 iteration: 2.16626\n",
      "('chat1 : ', ['hi', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['hello', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['hi', 'there', 'how', 'are', 'you', '', ''])\n",
      "('chat2 : ', ['i', 'am', 'fine', 'how', 'do', 'you', 'do'])\n",
      "('chat1 : ', ['i', 'am', 'doing', 'fine', '', '', ''])\n",
      "('chat2 : ', ['what', 'is', 'your', 'name', '', '', ''])\n",
      "('chat1 : ', ['hi', 'my', 'name', 'is', 'expectations', '', ''])\n",
      "('chat2 : ', ['you', 'are', 'indeed', 'expectations', '', '', ''])\n",
      "('chat1 : ', ['hello', 'apeksha', 'my', 'best', 'friend', '', ''])\n",
      "('chat2 : ', ['apeksha', 'is', 'expectations', '', '', '', ''])\n",
      "---------Training over------------\n",
      "---testing the trained model with test data----\n",
      "('chat1 : ', [['hi', 'how', 'are', 'you', '', '', '']])\n",
      "('chat_bot     : ', [['i', 'am', 'fine', 'how', 'do', 'you', 'do']])\n"
     ]
    }
   ],
   "source": [
    "#start of execution of training\n",
    "train_nn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
